---
title: Lead Data Analyst for TX31 Congressional Campaign
slug: on-data-tools-for-tx31
cover_photo: tx31/tx31-1.png
created_on: 2021-02-01
location: Austin, TX (Remote)
html: building_blocks/post-detail.html
tags:
---
__CONTENT__
!block
#### 1. Overview
From March 2020 to November 2020, I worked as a [Bluebonnet Data](https://www.bluebonnetdata.org/) fellow on the campaign of [Donna Imam](https://ballotpedia.org/Donna_Imam), a former computer engineer who sought to oust 9-term Republican incumbent John Carter for the U.S. Congressional seat in Texas’s 31st district. I joined the campaign in the wake of the initial Democratic primary elections, in which Imam was the runner up by a margin of about 5 points in a crowded field, initiating a runoff election cycle that would run through July 14th. During the runoff, I performed various analyses on demographic trends in the district to enable the campaign to efficiently target precincts for lit drop and compile lists of voters to phone-bank. Through extensive work coding in python and using the Texas Democratic party’s VAN, I also created a mapping software that provided daily updates to the campaign on their voter outreach progress and coordinated with their paid canvassers to inform them of next targets for lit drop and verify the hours they logged for payroll. On July 14th, Imam emerged as the clear winner by a 13 point margin, propelling the campaign to the general election contest on November 3rd. Throughout the Fall 2020 semester, I continued to complete various jobs relating to data and tech for the campaign (specific projects outlined in following sections). 

We had many reasons to be hopeful that we might succeed in flipping TX31: the Cook Political Report rated it as one of its swing districts (though under the category “Likely Republican”), 2020 Senate candidate MJ Hegar nearly flipped the seat in 2018, and demographic shifts in the past two years alone suggested that the district would likely be one to flip if Democrats up and down the ballot in Texas performed well in November. However, the record levels of both Repubican and Democrat turnout and the Republican down-ballot advantage proved to be too much for us, along with the entire crop of Texas Democratic Congressional challengers (none of whom won their races), to overcome. Imam ultimately lost by roughly 9 points to Carter, and in the post-election period, I have stayed on at her request to help her perform an [in-depth analysis](https://youtu.be/3ptZseYTHEg) of the election results to gain insight into the Democrats’ failure to flip Texas blue (see “Post Election” below). 

Despite the end result, I feel incredibly grateful to have had the opportunity to work on this campaign and am equally proud of the work I was able to do and how much I learned in the process. As Donna outlines in her post-election analysis, our team actually beat expectations significantly, coming much closer to victory despite having significantly less funding and name-ID than several of the other top 10 targeted U.S. House races. Like many others, I felt a strong moral obligation to work as hard as possible on this election in what may be our last, best chance to build a sustainable future before many of the consequences of our actions become irreversible. Working on this campaign and getting to personally know a candidate (a former engineer!) and a team who truly inspire me has been an amazing opportunity to do just that, and despite the many challenges that remain deeply troubling in the wake of this election, my experience in politics this year has ultimately left me with a strong sense of hope that I plan on carrying forward to my future activism. 
#### II. Data Dashboard
Using the Dash framework for python, I built an interactive [Data Dashboard](https://github.com/Dahlia-Dry/Campaign-Data-Dashboard) hosted with Heroku. It utilized univariate and bivariate analysis of data pulled from VAN and from election results archives, in addition to GIS data for mapping the precincts of TX31, to allow us to explore correlations between various factors such as turnout, voter demographics, election results, etc, that informed decisions on targeting resources for field organizing. The version of this Dashboard that I published to GitHub with publicly available sample data demonstrating some of its capabilities is still hosted on heroku and can be found at the link in the button below. The features this dashboard included while in active use are outlined in the following section.
!button https://tx31-data-dashboard-6a4f2f2baa16.herokuapp.com/ "click here to launch live demo"
- **Demographic Analysis (fig. 1):** This page on the dashboard allowed the user to toggle a large number of variables mapped to the precincts of TX31 (eg. # voters aged 18-24, Donna’s vote share in the runoff) and explore their distributions through histograms and their correlations through scatterplots.
- **Voter Targeting (fig. 2):** This page allowed us to calculate which precincts to prioritize for field organizing by assigning them scores based on weighted user-selected parameters. Fig. 2 shows the ranking of precincts in the top right quadrant based on four parameters with sliders (lower right quadrant) that allow the user to adjust their weights. The TX31 chloropleth (upper left quadrant) depicts darker precincts as stronger targets, and the user can hover to see exact stats for each precinct (lower left quadrant).
- **2020 Vote Tracker (fig.3):** This page was added with the start of early voting, and functioned as a live early vote tracker by scraping web data every time it was refreshed to get updated numbers for the early vote by day (Fig.3) as well as by polling place, which helped the campaign figure out where to send poll greeters and yard signs for maximum effectiveness. 
!figs tx31/tx31-1.png tx31/tx31-2.png tx31/tx31-3.png
#### III. Donor Database
As for any grassroots campaign, one of the biggest struggles throughout the general election was fundraising. So, doing things cost-efficiently was of paramount importance. For this purpose, considering the fact that the campaign already used the google suite of tools extensively for phone-banking etc, I developed a cost-free donor database with a google sheets interface that would allow us to circumvent paying for an alternative database that consultants had recommended we use. This allowed the campaign to conduct call and text campaigns to donors by making queries to a MySQL database I managed through a google sheets interface that I designed and customized to fit the needs of the people who were using it.
- **The Data:** Actblue records of previous campaign donors, combined with prospective donor records obtained periodically from Grassroots Analytics
- **MySQL Backend:** ​I wrote several python scripts to clean and process the donor data we got from ActBlue and Grassroots and merge new donors donor files to the database as we got them. This data was then hosted as a MySQL database via Google Cloud that could be queried by both my python scripts for maintenance and by the google sheets frontend that was used by other campaign personnel to generate call/text lists.
- **Google Sheets Frontend (fig.4):** I used google's built-in scripting tool to link a google sheet to the MySQL database. On the sheet, I set up a variety of fields in which a user could enter filter criteria, and then query the database to return results to the sheet, update entries and write the changes back to the database, and create formatted call lists for export. The sheet could be copied so that different people could use it and run different queries. This allowed multiple files to read and write  to a single source, which kept all our data up-to-date. As can be seen in Fig.4, there is an added "TX31 Donor Database" menu in the google sheets toolbar, which the user can click to perform the various actions of filtering data based on their entered criteria, writing changes back to the database, and exporting call lists.
- **Analytics (fig.5):**​​ ​In order to help figure out how to filter donors and prospective donors for targeting, I periodically ran analysis on the contents of the database. One such analysis, a timelapse of the amount donated vs number of individual donations by state, is depicted in Fig. 5, with the size of the bubble correlating to the number of people from that specific state we had in the database.
!figs tx31/tx31-4.png tx31/tx31-5.png
#### IV. Miscellaneous Tasks
Throughout the fall, I also completed several smaller projects relating to data and tech. I briefly co-opted my Data Dashboard and used Tax Appraisal GIS data to cut turfs for canvassers to do lit drop in Bell county (Fig. 6). I built a web scraper that ran Zillow queries on all the in-district addresses we had from VAN to get insight into median home prices by precinct and zipcode. I ran analysis on the district-level poll that was done by PPP in TX31 in the lead-up to the election (Fig. 7). I wrote several scripts to automate tasks relating to text-banking in Twilio, using its API to purchase large quantities of toll-free numbers, assign those numbers to text campaigns, and request usage logs. I pulled a lot of data from the Williamson and Bell county election archives to give us a more complete picture of previous election outcomes and differences between the congressional candidate and the top of the ticket.
!figs tx31/tx31-6.png tx31/tx31-7.png
#### V. Post election: [Data Deep Dive](https://youtu.be/3ptZseYTHEg)
In the aftermath of the November 3rd election, Donna asked me to continue working with her to perform an analysis of the election results in the 10 congressional districts with the strongest Democratic challengers in Texas (in addition to two with competitive Republican challengers). The biggest task here was to aggregate top-of ticket (i.e. President, Senate) results by congressional district instead of by county as they are reported, which involves mapping out which counties fall within which districts and then gathering both Texas Secretary of State data and precinct level reports from individual counties. I did this for 2016, 2018, and 2020 general election results (the part of the process where I use regression to screen for errors in my calculations is depicted in Fig. 8). Donna then used this data to compile a presentation (linked in the header above) on her insights into why Democrats lost in Texas in 2020. I also created several of the figures used in the presentation, one of which is Fig. 9.  
!figs tx31/tx31-8.png tx31/tx31-9.png

!endblock
__ENDCONTENT__
